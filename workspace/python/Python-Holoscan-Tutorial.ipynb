{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75003cf3",
   "metadata": {},
   "source": [
    "# Python Holoscan Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25b03b",
   "metadata": {},
   "source": [
    "Welcome to the Holoscan Python API tutorial! By now, you've learned some of the basic motivation, benefits, and architecture guiding Holoscan application development. Now, let's put some of that theory into practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea0a30",
   "metadata": {},
   "source": [
    "## Our First Holoscan Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df78d3",
   "metadata": {},
   "source": [
    "For our first Holoscan Application, we are going to create three operators:\n",
    "1. PingTxOp\n",
    "2. PingMiddleOp\n",
    "3. PingRxOp\n",
    "\n",
    "`PingTxOp` is our 'source' operator and generates integers that it emits via 2 ports, or streams, to the `PingMiddleOp` operator. This middle operator takes the two intergers transmitted by the source and multiplies both by a number, emitting both results (again, via 2 ports), to the `PingRxOp` operator. This final sink operator simply prints the results.\n",
    "\n",
    "Below is a diagram of the overall pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7544f5",
   "metadata": {},
   "source": [
    "<img src=\"images/MyPingApp.png\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126e0878",
   "metadata": {},
   "source": [
    "### Creating a Holoscan Custom Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe79157",
   "metadata": {},
   "source": [
    "Prior to creating a custom Holoscan Operator, we must import both `Operator` and `OperatorSpec` from `holoscan.core`\n",
    "- An operator is the most basic unit of work in this SDK. It receives streaming data at an input port, processes it, and publishes it to one of its output ports.\n",
    "- An operator can have multiple input and output ports. Further, in the case of a Source operator, where the main goal is to generate data, an operator may not have any input ports; conversely, a sink operator may not have any output ports.\n",
    "\n",
    "A Holoscan Operator is run based on logic defined in the scheduler. Diving into the guts of the scheduler is beyond the scope of this tutorial, but an Operator is 'run' with each clock tick, or iteration, emitted from the scheduler. Let's create a simple source Operator called PingTxOp that will transmit two outputs at each tick. Remember, since this is a source Operator, there are no input ports!\n",
    "\n",
    "In addition, the following examples will demonstrate the ability of operators to pass and operate on user-defined data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969abf60",
   "metadata": {},
   "source": [
    "#### User-defined data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueData:\n",
    "    \"\"\"Example of a custom Python class\"\"\"\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.data = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"ValueData({self.data})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.data == other.data\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc09a4c",
   "metadata": {},
   "source": [
    "Here is a simple wrapper for a user-defined data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f75b52",
   "metadata": {},
   "source": [
    "#### Custom Source Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e8a449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PingTxOp(Operator):\n",
    "    \"\"\"Simple transmitter operator.\n",
    "    This operator has:\n",
    "        outputs: \"out1\", \"out2\"\n",
    "    On each tick, it transmits a `ValueData` object at each port. The\n",
    "    transmitted values are even on port1 and odd on port2 and increment with\n",
    "    each call to compute.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.index = 0\n",
    "        # Need to call the base class constructor last\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        spec.output(\"out1\")\n",
    "        spec.output(\"out2\")\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        value1 = ValueData(self.index)\n",
    "        self.index += 1\n",
    "        op_output.emit(value1, \"out1\")\n",
    "\n",
    "        value2 = ValueData(self.index)\n",
    "        self.index += 1\n",
    "        op_output.emit(value2, \"out2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b2ef39",
   "metadata": {},
   "source": [
    "To define a Custom Operator in Holoscan, the developer must first create a Python class that inherits from the `holoscan.core.Operator` class. In this case, we are creating an Operator named `PingTxOp`.\n",
    "\n",
    "Regardless of the Operator's function, Custom Holoscan Operators each contain:\n",
    "- An `__init__` function used to initialize class specific parameters\n",
    "- A `setup` function used to define input and output ports\n",
    "- A `compute` function that defines the compute or work done within that Operator\n",
    "\n",
    "**More on the Setup Function**\n",
    "`setup` sources from the `OperatorSpec` class which can then be directly used to define that Operator's inputs and outputs. \n",
    "\n",
    "To create an input port:\n",
    "`spec.input(\"name_of_port\")` where \"name_of_port\" is your name for the operator input port\n",
    "\n",
    "To create an output port:\n",
    "`spec.output(\"name_of_port\")` where \"name_of_port\" is your name for the operator output port\n",
    "\n",
    "These output port names, of course, must be unique.\n",
    "\n",
    "**More on the Compute Function**\n",
    "Most of your application specfic code will take place in the Operator's `compute` function. As you can see in the example above, the `compute` function allows for three separate parameters to be passed in, by default, to the function. We will focus on `op_input` and `op_output` in detail.\n",
    "\n",
    "`op_input` provides the mechanism to receiving upstream messages and data into the custom Holoscan Operator.\n",
    "\n",
    "To receive data from an upstream operator:\n",
    "`value = op_input.receive(\"name_of_port\")` where \"name_of_port\" is the name of the input port on which data is received. Here, `value` could be an integer, tensor, or other Python data object. Later in the tutorial, we will build applications that invoke compute on the incoming data stream.\n",
    "\n",
    "To emit data and messages from the operator:\n",
    "`op_output.emit(value, \"name_of_port\")` where `value` is the data object you want to send out of the operator and \"name_of_port\" is the port name to emit the data stream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb5f13a",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa18bf0",
   "metadata": {},
   "source": [
    "Now that we have some familarity with building custom Holoscan Operators, please fix the \"FIX ME\" in the below code to construct a custom Operator named `MyOp` that has following:\n",
    "- 3 input ports, named `in1`, `in2`, and `in3`\n",
    "- 2 output ports, named `out1`, `out2`\n",
    "- In the `compute` function, always emit the data received on `in1` with the `out1` port\n",
    "- Emit `in2` with `out2` if the Operator tick (hint: leverage `self.index`) is odd and `in3` with `out2` if the tick is even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c213ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class <<<FIX ME>>>(<<<FIX ME>>>):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.index = 0\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        spec.input(<<<FIX ME>>>)\n",
    "        spec.input(<<<FIX ME>>>)\n",
    "        spec.input(<<<FIX ME>>>)\n",
    "        spec.output(<<<FIX ME>>>)\n",
    "        spec.output(<<<FIX ME>>>)\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        \n",
    "        # Always emit in1 value in out1 port\n",
    "        in1_value = op_input.receive(<<<FIX ME>>>)\n",
    "        op_output.emit(in1_value, <<<FIX ME>>>)\n",
    "\n",
    "        # each input needs to be received, regardless of utilization\n",
    "        # Even if in2 and in3 won't be utilized at the same time,\n",
    "        # they still both need to be be received\n",
    "        in2_value = op_input.receive(<<<FIX ME>>>)\n",
    "        in3_value = op_input.receive(<<<FIX ME>>>)\n",
    "        \n",
    "        # If tick is even\n",
    "        if <<<FIX ME>>>:   \n",
    "            op_output.emit(in2_value, \"out2\")\n",
    "        else:\n",
    "            op_output.emit(in3_value, \"out2\")\n",
    "        \n",
    "        self.index += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed256f8b",
   "metadata": {},
   "source": [
    "Click [here](scripts/answers/ex1.py) to view the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bcb0ae",
   "metadata": {},
   "source": [
    "#### Custom Middle Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def9b7af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PingMiddleOp(Operator):\n",
    "    \"\"\"Example of an operator modifying data.\n",
    "    This operator has:\n",
    "        inputs:  \"in1\", \"in2\"\n",
    "        outputs: \"out1\", \"out2\"\n",
    "    The data from each input is multiplied by a user-defined value.\n",
    "    In this demo, the `multiplier` parameter value is read from a \"ping.yaml\"\n",
    "    configuration file (near the bottom of this script), overriding the default\n",
    "    defined in the setup() method below.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # If `self.multiplier` is set here (e.g., `self.multiplier = 4`), then\n",
    "        # the default value by `param()` in `setup()` will be ignored.\n",
    "        # (you can just call `spec.param(\"multiplier\")` in `setup()` to use the\n",
    "        # default value)\n",
    "        \n",
    "        # self.multiplier = 4\n",
    "        self.count = 1\n",
    "\n",
    "        # Need to call the base class constructor last\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        spec.input(\"in1\")\n",
    "        spec.input(\"in2\")\n",
    "        spec.output(\"out1\")\n",
    "        spec.output(\"out2\")\n",
    "        spec.param(\"multiplier\", 2)\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        value1 = op_input.receive(\"in1\")\n",
    "        value2 = op_input.receive(\"in2\")\n",
    "        print(f\"Middle message received (count: {self.count})\")\n",
    "        self.count += 1\n",
    "\n",
    "        print(f\"Middle message value1: {value1.data}\")\n",
    "        print(f\"Middle message value2: {value2.data}\")\n",
    "\n",
    "        # Multiply the values by the multiplier parameter\n",
    "        value1.data *= self.multiplier\n",
    "        value2.data *= self.multiplier\n",
    "\n",
    "        op_output.emit(value1, \"out1\")\n",
    "        op_output.emit(value2, \"out2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093cf48a",
   "metadata": {},
   "source": [
    "This middle operator receives two channels of input data from `PingTxOp` and then multiplies each output by a certain value. The resulting integer is then emitted out of the middle operator via its two ports.\n",
    "\n",
    "While `PingMiddleOp` is performing more work than the `PingTxOp` Operator, one can immediately find similaries in both structure and implementation between the two. Providing boiler-plate mechanisms to build applications is the soul of Holoscan!\n",
    "\n",
    "Many Holoscan Operators are accompanied by a YAML configuration file that defines specific parameters to be used in that Operator. We will look at more examples later, but for AI inferencing Operators, these YAML files define things like the path to a trained ONNX model, a TensorRT inference engine, and data paths. By using configuration files, we can simplify the application code and improve portability.\n",
    "\n",
    "In this example, we are obtaining the `multiplier` value from a corresponding [ping.yaml](scripts/ping/ping.yaml) file, and referenced with `spec.param`. This could easily be defined within the operator, however."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65e419",
   "metadata": {},
   "source": [
    "#### Custom Sink Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d666fbdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PingRxOp(Operator):\n",
    "    \"\"\"Simple receiver operator.\n",
    "    This operator has:\n",
    "        input: \"receivers\"\n",
    "    This is an example of a native operator that can dynamically have any\n",
    "    number of inputs connected to is \"receivers\" port.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.count = 1\n",
    "        # Need to call the base class constructor last\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        spec.param(\"receivers\", kind=\"receivers\")\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        values = op_input.receive(\"receivers\")\n",
    "        print(f\"Rx message received (count: {self.count}, size: {len(values)})\")\n",
    "        self.count += 1\n",
    "        print(f\"Rx message value1: {values[0].data}\")\n",
    "        print(f\"Rx message value2: {values[1].data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e40cb4",
   "metadata": {},
   "source": [
    "You should be a pro by now! With this `PingRxOp` sink Operator, we won't have any output messages; this Operator is mainly used to print the message received from an upstream operator. Other sink operator examples include a Visualizer (we'll speak more about HoloViz later) or audio/signal playback tools.\n",
    "\n",
    "For this specific Operator, we are showing how to programmatically define input ports with the special `receivers` parameter (note the `kind='receivers'` keyword argument); in this case, we can dynamically have any number of inputs connected to the Operator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f63060",
   "metadata": {},
   "source": [
    "### Connect Operators to Form an Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef4688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from holoscan.conditions import CountCondition\n",
    "from holoscan.core import Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b5250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyPingApp(Application):\n",
    "    def compose(self):\n",
    "        # Configure the operators. Here we use CountCondition to terminate\n",
    "        # execution after a specific number of messages have been sent.\n",
    "        tx = PingTxOp(self, CountCondition(self, 10), name=\"tx\")\n",
    "        mx = PingMiddleOp(self, self.from_config(\"mx\"), name=\"mx\")\n",
    "        rx = PingRxOp(self, name=\"rx\")\n",
    "\n",
    "        # Connect the operators into the workflow:  tx -> mx -> rx\n",
    "        self.add_flow(tx, mx, {(\"out1\", \"in1\"), (\"out2\", \"in2\")})\n",
    "        self.add_flow(mx, rx, {(\"out1\", \"receivers\"), (\"out2\", \"receivers\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb591c",
   "metadata": {},
   "source": [
    "Now that we have a series of custom Holoscan Operators, we need to define data movement by connecting them all together in an application.\n",
    "\n",
    "Similar to Holoscan Operators, a Holoscan Application inherits from the `holoscan.core.Application` module. It contains a single function, `compose` (in addition to `__init__` that isn't shown in the example above). Within the `compose` function, we instantiate our custom (or core - to be discussed later) operators, name them, and connect them together with `self.add_flow`.\n",
    "\n",
    "When connecting operators, `add_flow` takes the following arguments:\n",
    "- Upstream operator\n",
    "- Downstream operator\n",
    "- How ports are connected - these are defined by a Python set of 2-tuples specifying the port names to connect, e.g. {(source_port_name, destination_port_name)}\n",
    "\n",
    "In the example above, `self.add_flow(tx, mx, {(\"out1\", \"in1\"), (\"out2\", \"in2\")})` connects the `PingTxOp` to `PingMxOp` and maps the output of `out1` in `PingTxOp` to the input `in1` in `PingMxOp` along with the output of `out1` in `PingTxOp` to the input `in2` in `PingMxOp`.\n",
    "\n",
    "One other parameter you may notice is `CountCondition(self, 10)` in the source Operator. This helps define how often the Operator 'ticks', or is executed sequentially. There are a few control options:\n",
    "- CountCondtion - Tick for N number of times\n",
    "- BooleanCondition - Programmatically tick (e.g. always tic until false)\n",
    "- MessageAvailableCondition - Tick when message is received"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbfeb35",
   "metadata": {},
   "source": [
    "### Run Ping Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2384edc",
   "metadata": {},
   "source": [
    "In order to run the `MyPingApp`, please run the cell below and pay close attention to the output. Please note, this ping application leverages a config yaml specified in the source code when launching the application.\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    app = MyPingApp()\n",
    "    app.config(os.path.join(os.path.dirname(__file__), \"ping.yaml\"))\n",
    "    app.run()\n",
    "```\n",
    "\n",
    "If you don't have a yaml config file, use `app.config(\"\")`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7828de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python scripts/ping/ping.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45b911e",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c4ee1",
   "metadata": {},
   "source": [
    "Now it's your turn to code! Modify [ping-pow.py](scripts/exercises/ping-pow.py) to create a new operator called `Pow2on2` that squares the incoming integers if the clock tick is even. Otherwise, pass through the data. Be sure to swap out the `PingMiddleOp` above with `Pow2on2` and examine the output to ensure correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6bc539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TO-DO\n",
    "# 1) edit ping-pow.py (link above)\n",
    "\n",
    "# 2) Run application using the following command\n",
    "!python scripts/exercises/ping-pow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9bc8ae-c10f-43c8-bb9a-499195a37a91",
   "metadata": {},
   "source": [
    "Click [here](scripts/answers/ex2.py) to view the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df557b6",
   "metadata": {},
   "source": [
    "## Building Holoscan Applications with GPU-Accelerated Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8badab26",
   "metadata": {},
   "source": [
    "Let's move onto a more interesting example. One of the most exciting features of the Holoscan Python APIs is that it supports passing Python Objects between operators. This means that developers can easily leverage existing GPU-accelerated Python libraries in their streaming sensor workflows like:\n",
    "- [CuPy](https://cupy.dev) - A GPU-accelerated version of NumPy for Numerical Computing\n",
    "- [RAPIDS](https://rapids.ai) - A colleciton of GPU-accelerated data science libraries\n",
    "- [PyTorch](https://pytorch.org) - GPU-accelerated deep learning framework for AI training and inferencing\n",
    "- [JAX](https://github.com/google/jax) - Differentiable numerical computing library with GPU support\n",
    "- [Numba](https://numba.pydata.org/) - LLVM JIT compiler that allows for the formulaic construction of GPU kernels in Python\n",
    "\n",
    "Let's look at an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a647293",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fourier Transforms with CuPy and Holoscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d85a049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFTOp(Operator):\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        spec.input(\"time_in\")\n",
    "        spec.output(\"frequency_out\")\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        sig = op_input.receive(\"time_in\")\n",
    "        op_output.emit(cp.fft.fft(sig), \"sig_out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c915acfb",
   "metadata": {},
   "source": [
    "In this example, we create a custom `FFTOp` Holoscan Operator that accepts an input data stream, runs an FFT with CuPy on that tensor, and emits the result out of the operator. One thing to note is that we can simpy run the `cupy.fft` function on the data captured from Holoscan's `op_input.receive` function. There are, however, certain cases where the developer needs use a \"Holoscan Tensor\", notably when they're leveraging Operators that are packaged with the Holoscan SDK. We discuss this in depth below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad748f",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe43472e",
   "metadata": {},
   "source": [
    "Create a Holoscan application that consists of three operators:\n",
    "1. SourceOp - Emits 3 ticks of random arrays of size 32,768 samples\n",
    "2. FFTOp - Performs FFT on data streaming from SourceOp\n",
    "3. SinkOp - Prints results of FFTOp\n",
    "\n",
    "Click here to open [fftapp.py](scripts/exercises/fftapp.py). Please note, we do not need a config file for this example.\n",
    "\n",
    "As a hint, one can create a random valued array in cupy with `cupy.random.randn(size_of_array)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47404b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO\n",
    "# 1) edit fftapp.py (link above)\n",
    "\n",
    "# 2) Run application using the following command\n",
    "!python scripts/exercises/fftapp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52875ae-5d72-47fe-a4ca-d520489ed4e0",
   "metadata": {},
   "source": [
    "Click [here](scripts/answers/ex3.py) to view the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd9933",
   "metadata": {},
   "source": [
    "### Decorators: turn any function into an operator\n",
    "Decorators have been introduced in HSDK-2.3.0. \n",
    "\n",
    "Decoraters come in handy when one wishes to turn a data analysis script into a production-ready Holoscan pipeline. With decorators, one can turn any function into an operator, which greatly reduces the refactoring overhead associated with Holoscan adoption.\n",
    "\n",
    "Quick note: this is still an experimental feature - API is still under development. The HSDK team is accepting user community feedback and will be happy to update the API in the upcoming releases.\n",
    "\n",
    "Here is an example of the fft app, but written with decorators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from holoscan.conditions import CountCondition\n",
    "from holoscan.core import Application\n",
    "from holoscan.decorator import create_op\n",
    "import cupy as cp\n",
    "\n",
    "@create_op(outputs=\"signal\")\n",
    "def src_func():\n",
    "    signal = cp.random.randn(32768)\n",
    "    return signal\n",
    "\n",
    "@create_op(inputs=\"signal\", outputs=\"signal_fft\")\n",
    "def fft_func(signal):\n",
    "    return cp.fft.fft(signal)\n",
    "\n",
    "@create_op(inputs=\"signal_fft\")\n",
    "def sink_func(signal_fft):\n",
    "    print(signal_fft)\n",
    "\n",
    "\n",
    "class FFTApp_with_decorators(Application):\n",
    "    def compose(self):\n",
    "        src = src_func(self, CountCondition(self, 3), name='src_op')\n",
    "        fft = fft_func(self, name='fft_op')\n",
    "        sink = sink_func(self, name='sink_op')\n",
    "\n",
    "        # Connect the operators into the workflow:  src -> fft -> sink\n",
    "        self.add_flow(src, fft)\n",
    "        self.add_flow(fft, sink)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = FFTApp_with_decorators()\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b842e",
   "metadata": {},
   "source": [
    "If the pipeline is non-linear, i.e. different data streams move across different operators, decorators can be configured to receive/transmit only relevant variables using helper classes `Input` and `Output`. Here is an example of a pipeline where `signal1` goes through an FFT operator and `signal2` is doubled in amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a9b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from holoscan.decorator import Input, Output\n",
    "@create_op(outputs=(Output(\"signal1\", tensor_names=(\"signal1\",)),\n",
    "                    Output(\"signal2\", tensor_names=(\"signal2\",))))\n",
    "def src_func():\n",
    "    signal1 = cp.random.randn(32768)\n",
    "    signal2 = cp.random.randn(32768)\n",
    "    return {\"signal1\": signal1,\n",
    "            \"signal2\": signal2} # note that this is now a dict\n",
    "\n",
    "# This one is rewritten to demonstate handling of input/output variables in the most general case\n",
    "@create_op(inputs=(Input(\"signal1\", arg_map=\"signal1\"),),\n",
    "           outputs=(Output(\"signal1_fft\", tensor_names=(\"signal1_fft\",)),))\n",
    "def fft_func(signal1):\n",
    "    return {\"signal1_fft\": cp.fft.fft(signal1)}\n",
    "\n",
    "# In linear sections of pipelines details in decorator configurations can be omitted\n",
    "@create_op(inputs=\"signal2\", outputs=\"signal2_double\")\n",
    "def double_func(signal2):\n",
    "    return signal2 * 2\n",
    "\n",
    "@create_op(inputs=(Input(\"signal1_fft\", arg_map=\"signal1_fft\"),\n",
    "                   Input(\"signal2_double\", arg_map=\"signal2_double\")))\n",
    "def sink_func(signal1_fft, signal2_double):\n",
    "    print(f\"{signal1_fft=}\")\n",
    "    print(f\"{signal2_double=}\")\n",
    "\n",
    "\n",
    "class FFTApp_with_decorators(Application):\n",
    "    def compose(self):\n",
    "        src = src_func(self, CountCondition(self, 3), name='src_op')\n",
    "        fft = fft_func(self, name='proc_op')\n",
    "        double = double_func(self, name='double_func')\n",
    "        sink = sink_func(self, name='sink_op')\n",
    "\n",
    "        # Connect the operators into the workflow:  src -> fft -> sink\n",
    "        self.add_flow(src, fft, {(\"signal1\", \"signal1\")})\n",
    "        self.add_flow(src, double, {(\"signal2\", \"signal2\")})\n",
    "        self.add_flow(fft, sink, {(\"signal1_fft\", \"signal1_fft\")})\n",
    "        self.add_flow(double, sink, {(\"signal2_double\", \"signal2_double\")})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = FFTApp_with_decorators()\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ab6af",
   "metadata": {},
   "source": [
    "### Challenge Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ab6ed",
   "metadata": {},
   "source": [
    "Create a Holoscan application that performs a matrix multiplication between a constant matrix and an updating one. This application should:\n",
    "1. Include a SourceOp that emits 5 ticks of 1000x10 random values that updates with each tick along with a 1000x1000 random value matrix that doesn't change.\n",
    "2. Include a MatMulOp that performs the matrix multiplication\n",
    "3. Include a SinkOp that prints the last row in the resulting matrix\n",
    "\n",
    "Click here to open [challenge-exercise.py](scripts/exercises/challenge-exercise.py).\n",
    "\n",
    "As a hint, one can create a random generator via `rng = cp.random.default_rng()` and then create a single precision random valued matrix with `rng.standard_normal((num_rows, num_cols), dtype=cp.float32)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO\n",
    "\n",
    "# 1) Update challenge-exercise.py (link above)\n",
    "\n",
    "# 2) Run application using the following command\n",
    "!python scripts/exercises/challenge-exercise.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b4e21c-71c0-4836-9939-9809b308bc38",
   "metadata": {},
   "source": [
    "Click [here](scripts/answers/ex3-challenge.py) to view the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c6e5d4",
   "metadata": {},
   "source": [
    "## Using Pre-Built Holoscan Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de0b2d",
   "metadata": {},
   "source": [
    "We have currently only discussed creating custom Operators, but there are a selection of optimized Operators that come packaged with the Holoscan SDK. These are available within the `holoscan.operators` and `holohub` module and include Operators that define commonly used functions when building real-time streaming AI pipelines.\n",
    "\n",
    "A few examples:\n",
    "- **Video Stream Replayer** - Outputs video frames as Holoscan Tensor objects\n",
    "- **Holoviz** - High speed viewer that handles composing, blending, and visualzation of RBG and RGBA images, masks, geometric primitives, and text\n",
    "- **AJA Source** - Enables GPU-Direct RDMA on Quadro/RTX GPUs with AJA capture card\n",
    "- **Inference Module** - Provides capabilites to execute AI inference on one or multiple models\n",
    "\n",
    "These core operators can be used just like the custom ones above and are typically configured via an appliation YAML file that specifies items like image size, model location, TensorRT engine location, and other important parameters.\n",
    "\n",
    "You can find out more about the Core Holoscan Operators by reading the [User Guide](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html).\n",
    "\n",
    "Let's see how some of these pre-built Operators can be leveraged in an AI-enabled sensor pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb929505",
   "metadata": {},
   "source": [
    "### TAO PeopleNet Detection Model on V4L2 Video Stream - A Basic Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1455ed",
   "metadata": {},
   "source": [
    "In this example, we use the TAO PeopleNet available on NGC to detect faces and people in a V4L2 supported video stream. This pipeline makes use of 4 core Holoscan Operators:\n",
    "1. Video Stream Replayer\n",
    "2. Format Converter - Converts data type of the image from `uint8` to `float32` and resizes the image\n",
    "3. Inference Module - Performs inference of the segmentation model with TensorRT\n",
    "4. Holoviz - Shows tool tracking results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a42ad",
   "metadata": {},
   "source": [
    "<img src=\"images/face_and_people_detection_app.png\" width=1000/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import holoscan as hs\n",
    "import numpy as np\n",
    "from holoscan.core import Application, Operator, OperatorSpec\n",
    "from holoscan.gxf import Entity\n",
    "from holoscan.operators import (\n",
    "    VideoStreamReplayerOp,\n",
    "    FormatConverterOp,\n",
    "    InferenceOp,\n",
    "    HolovizOp,\n",
    ")\n",
    "from holoscan.resources import UnboundedAllocator\n",
    "from holoscan.schedulers import GreedyScheduler\n",
    "from argparse import ArgumentParser \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17793e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessorOp(Operator):\n",
    "    \"\"\"Operator to format input image for inference\"\"\"\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        spec.input(\"in\")\n",
    "        spec.output(\"out\")\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        # Get input message\n",
    "        in_message = op_input.receive(\"in\")\n",
    "\n",
    "        # Transpose\n",
    "        tensor = cp.asarray(in_message.get(\"preprocessed\")).get()\n",
    "        # OBS: Numpy conversion and moveaxis is needed to avoid strange\n",
    "        # strides issue when doing inference\n",
    "        tensor = np.moveaxis(tensor, 2, 0)[None]\n",
    "        tensor = cp.asarray(tensor)\n",
    "\n",
    "        # Create output message\n",
    "        out_message = {\"preprocessed\": tensor}\n",
    "        op_output.emit(out_message, \"out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be04e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostprocessorOp(Operator):\n",
    "    \"\"\"Operator to post-process inference output:\n",
    "    * Reparameterize bounding boxes\n",
    "    * Non-max suppression\n",
    "    * Make boxes compatible with Holoviz\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        spec.input(\"in\")\n",
    "        spec.output(\"out\")\n",
    "        spec.param(\"iou_threshold\", 0.15)\n",
    "        spec.param(\"score_threshold\", 0.5)\n",
    "        spec.param(\"image_width\", None)\n",
    "        spec.param(\"image_height\", None)\n",
    "        spec.param(\"box_scale\", None)\n",
    "        spec.param(\"box_offset\", None)\n",
    "        spec.param(\"grid_height\", None)\n",
    "        spec.param(\"grid_width\", None)\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        # Get input message\n",
    "        in_message = op_input.receive(\"in\")\n",
    "\n",
    "        # Convert input to cupy array\n",
    "        boxes = cp.asarray(in_message.get(\"boxes\"))[0, ...]\n",
    "        scores = cp.asarray(in_message.get(\"scores\"))[0, ...]\n",
    "\n",
    "        # PeopleNet has three classes:\n",
    "        # 0. Person\n",
    "        # 1. Bag\n",
    "        # 2. Face\n",
    "        # Here we only keep the Person and Face classes\n",
    "        boxes = boxes[[0, 1, 2, 3, 8, 9, 10, 11], ...][None]\n",
    "        scores = scores[[0, 2], ...][None]\n",
    "\n",
    "        # Loop over label classes\n",
    "        out = {\"person\": None, \"faces\": None}\n",
    "        for i, label in enumerate(out):\n",
    "            # Reparameterize boxes\n",
    "            out[label], scores_nms = self.reparameterize_boxes(\n",
    "                boxes[:, 0 + i * 4 : 4 + i * 4, ...],\n",
    "                scores[:, i, ...][None],\n",
    "            )\n",
    "\n",
    "            # Non-max suppression\n",
    "            out[label], _ = self.nms(out[label], scores_nms)\n",
    "\n",
    "            # Reshape for HoloViz\n",
    "            if len(out[label]) == 0:\n",
    "                out[label] = np.zeros([1, 2, 2]).astype(np.float32)\n",
    "            else:\n",
    "                out[label][:, [0, 2]] /= self.image_width\n",
    "                out[label][:, [1, 3]] /= self.image_height\n",
    "                out[label] = cp.reshape(out[label][None], (1, -1, 2))\n",
    "\n",
    "        # Create output message\n",
    "        op_output.emit(out, \"out\")\n",
    "\n",
    "    def nms(self, boxes, scores):\n",
    "        \"\"\"Non-max suppression (NMS)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        boxes : array (4, n)\n",
    "        scores : array (n,)\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        boxes : array (m, 4)\n",
    "        scores : array (m,)\n",
    "\n",
    "        \"\"\"\n",
    "        if len(boxes) == 0:\n",
    "            return cp.asarray([]), cp.asarray([])\n",
    "\n",
    "        # Get coordinates\n",
    "        x0, y0, x1, y1 = boxes[0, :], boxes[1, :], boxes[2, :], boxes[3, :]\n",
    "\n",
    "        # Area of bounding boxes\n",
    "        area = (x1 - x0 + 1) * (y1 - y0 + 1)\n",
    "\n",
    "        # Get indices of sorted scores\n",
    "        indices = cp.argsort(scores)\n",
    "\n",
    "        # Output boxes and scores\n",
    "        boxes_out, scores_out = [], []\n",
    "\n",
    "        # Iterate over bounding boxes\n",
    "        while len(indices) > 0:\n",
    "            # Get index with highest score from remaining indices\n",
    "            index = indices[-1]\n",
    "\n",
    "            # Pick bounding box with highest score\n",
    "            boxes_out.append(boxes[:, index])\n",
    "            scores_out.append(scores[index])\n",
    "\n",
    "            # Get coordinates\n",
    "            x00 = cp.maximum(x0[index], x0[indices[:-1]])\n",
    "            x11 = cp.minimum(x1[index], x1[indices[:-1]])\n",
    "            y00 = cp.maximum(y0[index], y0[indices[:-1]])\n",
    "            y11 = cp.minimum(y1[index], y1[indices[:-1]])\n",
    "\n",
    "            # Compute IOU\n",
    "            width = cp.maximum(0, x11 - x00 + 1)\n",
    "            height = cp.maximum(0, y11 - y00 + 1)\n",
    "            overlap = width * height\n",
    "            union = area[index] + area[indices[:-1]] - overlap\n",
    "            iou = overlap / union\n",
    "\n",
    "            # Threshold and prune\n",
    "            left = cp.where(iou < self.iou_threshold)\n",
    "            indices = indices[left]\n",
    "\n",
    "        # To array\n",
    "        boxes = cp.asarray(boxes_out)\n",
    "        scores = cp.asarray(scores_out)\n",
    "\n",
    "        return boxes, scores\n",
    "\n",
    "    def reparameterize_boxes(self, boxes, scores):\n",
    "        \"\"\"Reparameterize boxes from corner+width+height to corner+corner.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        boxes : array (1, 4, grid_height, grid_width)\n",
    "        scores : array (1, 1, grid_height, grid_width)\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        boxes : array (4, n)\n",
    "        scores : array (n,)\n",
    "\n",
    "        \"\"\"\n",
    "        cell_height = self.image_height / self.grid_height\n",
    "        cell_width = self.image_width / self.grid_width\n",
    "\n",
    "        # Generate the grid coordinates\n",
    "        mx, my = cp.meshgrid(cp.arange(self.grid_width), cp.arange(self.grid_height))\n",
    "        mx = mx.astype(np.float32).reshape((1, 1, self.grid_height, self.grid_width))\n",
    "        my = my.astype(np.float32).reshape((1, 1, self.grid_height, self.grid_width))\n",
    "\n",
    "        # Compute the box corners\n",
    "        xmin = -(boxes[0, 0, ...] + self.box_offset) * self.box_scale + mx * cell_width\n",
    "        ymin = -(boxes[0, 1, ...] + self.box_offset) * self.box_scale + my * cell_height\n",
    "        xmax = (boxes[0, 2, ...] + self.box_offset) * self.box_scale + mx * cell_width\n",
    "        ymax = (boxes[0, 3, ...] + self.box_offset) * self.box_scale + my * cell_height\n",
    "        boxes = cp.concatenate([xmin, ymin, xmax, ymax], axis=1)\n",
    "\n",
    "        # Select the scores that are above the threshold\n",
    "        scores_mask = scores > self.score_threshold\n",
    "        scores = scores[scores_mask]\n",
    "        scores_mask = cp.repeat(scores_mask, 4, axis=1)\n",
    "        boxes = boxes[scores_mask]\n",
    "\n",
    "        # Reshape after masking\n",
    "        n = int(boxes.size / 4)\n",
    "        boxes = boxes.reshape(4, n)\n",
    "\n",
    "        return boxes, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeopleAndFaceDetectApp(Application):\n",
    "    def __init__(self, data_path, model_path, *args, **kwargs):\n",
    "        \"\"\"Initialize the face and people detection application\"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.name = \"People and Face Detection App\"\n",
    "        self.sample_data_path = data_path\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def compose(self):\n",
    "        pool = UnboundedAllocator(self, name=\"pool\")\n",
    "\n",
    "        # Video source operator\n",
    "        source = VideoStreamReplayerOp(\n",
    "            self,\n",
    "            name=\"replayer_source\",\n",
    "            directory=self.sample_data_path,\n",
    "            **self.kwargs(\"replayer_source\"),\n",
    "        )\n",
    "\n",
    "        # Format converter operator\n",
    "        preprocessor_args = self.kwargs(\"preprocessor\")\n",
    "        format_converter = FormatConverterOp(\n",
    "            self,\n",
    "            name=\"preprocessor\",\n",
    "            pool=pool,\n",
    "            **preprocessor_args,\n",
    "        )\n",
    "\n",
    "        # Preprocessor operator\n",
    "        preprocessor = PreprocessorOp(\n",
    "            self,\n",
    "            name=\"transpose\",\n",
    "            pool=pool,\n",
    "        )\n",
    "\n",
    "        # Inference operator\n",
    "        inference_args = self.kwargs(\"inference\")\n",
    "        inference_args[\"model_path_map\"] = {\n",
    "            \"face_detect\": os.path.join(self.sample_data_path, \"resnet34_peoplenet_int8.onnx\")\n",
    "        }\n",
    "\n",
    "        inference = InferenceOp(\n",
    "            self,\n",
    "            name=\"inference\",\n",
    "            allocator=pool,\n",
    "            **inference_args,\n",
    "        )\n",
    "\n",
    "        # Postprocessor operator\n",
    "        postprocessor_args = self.kwargs(\"postprocessor\")\n",
    "        postprocessor_args[\"image_width\"] = preprocessor_args[\"resize_width\"]\n",
    "        postprocessor_args[\"image_height\"] = preprocessor_args[\"resize_height\"]\n",
    "        postprocessor = PostprocessorOp(\n",
    "            self,\n",
    "            name=\"postprocessor\",\n",
    "            allocator=pool,\n",
    "            **postprocessor_args,\n",
    "        )\n",
    "\n",
    "        # Vizualization operator\n",
    "        holoviz = HolovizOp(self,\n",
    "                            allocator=pool,\n",
    "                            name=\"holoviz\",\n",
    "                            headless=True, # this True to run the app on the cluster (see below)\n",
    "                            **self.kwargs(\"holoviz\"))\n",
    "\n",
    "\n",
    "        self.add_flow(source, holoviz, {(\"output\", \"receivers\")})\n",
    "        self.add_flow(source, format_converter)\n",
    "        self.add_flow(format_converter, preprocessor)\n",
    "        self.add_flow(preprocessor, inference, {(\"\", \"receivers\")})\n",
    "        self.add_flow(inference, postprocessor, {(\"transmitter\", \"in\")})\n",
    "        self.add_flow(postprocessor, holoviz, {(\"out\", \"receivers\")})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config_file = os.path.join(os.path.dirname(__file__), \"tao_peoplenet.yaml\")\n",
    "    data_path = os.path.join(os.path.dirname(__file__), \"data/\")\n",
    "    model_path = os.path.join(os.path.dirname(__file__), \"data/resnet34_peoplenet_int8.onnx\")\n",
    "\n",
    "    app = PeopleAndFaceDetectApp(data_path, model_path)\n",
    "    app.config(config_file)\n",
    "    scheduler = GreedyScheduler(app, name=\"greedy_scheduler\", max_duration_ms=5000)\n",
    "    app.scheduler(scheduler)\n",
    "\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5b0dd",
   "metadata": {},
   "source": [
    "Let's take a look at the contents of the [config file](scripts/tao_peoplenet/tao_peoplenet.yaml) as well:\n",
    "```python\n",
    "replayer_source:\n",
    "  basename: \"people\"\n",
    "  frame_rate: 0   # as specified in timestamps\n",
    "  repeat: true    # default: false\n",
    "  count: 0        # default: 0 (no frame count restriction)\n",
    "\n",
    "preprocessor:\n",
    "  in_dtype: \"rgb888\" # input data type for format converter\n",
    "  out_tensor_name: preprocessed\n",
    "  out_dtype: \"float32\"\n",
    "  resize_width: 960\n",
    "  resize_height: 544\n",
    "  scale_min: 0.0\n",
    "  scale_max: 1.0\n",
    "\n",
    "inference:\n",
    "  backend: \"trt\"\n",
    "  pre_processor_map:\n",
    "    \"face_detect\": [\"preprocessed\"]\n",
    "  inference_map:\n",
    "    \"face_detect\": [\"scores\", \"boxes\"]\n",
    "  device_map:\n",
    "    \"face_detect\": \"0\"\n",
    "  input_on_cuda: true\n",
    "  is_engine_path: false\n",
    "\n",
    "postprocessor:\n",
    "  iou_threshold: 0.15\n",
    "  score_threshold: 0.5\n",
    "  box_scale: 35.0\n",
    "  box_offset: 0.5\n",
    "  grid_height: 34\n",
    "  grid_width: 60\n",
    "\n",
    "holoviz:\n",
    "  tensors:\n",
    "    - name: \"\"\n",
    "      type: color\n",
    "    - name: faces\n",
    "      type: rectangles\n",
    "      opacity: 0.5\n",
    "      line_width: 4\n",
    "      color: [1.0, 0.0, 0.0, 1.0]\n",
    "    - name: person\n",
    "      type: rectangles\n",
    "      opacity: 0.5\n",
    "      line_width: 4\n",
    "      color: [0.0, 1.0, 0.0, 1.0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587d125",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5233f09",
   "metadata": {},
   "source": [
    "Now the app can be run! Here we can see the output of the app. Note that on the first launch the app will build the NN engine to run it on the specific GPU that is available on the machine. \n",
    "\n",
    "\n",
    "Unfortunately, HoloViz launches an X11 display window that isn't well suited for use within a Jupyter Notebook and/or cluster environment. Since the output cannot be seen, we time out the app after 5 seconds. Because of this timeout, one might need to run the following snippet twice since the NN engine building can take a bit more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeecaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./scripts/tao_peoplenet/tao_peoplenet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d55420c",
   "metadata": {},
   "source": [
    "If you took this code on your own machine and ran it, you'd see the following results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a605392e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/ultrasound_segmentation.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"./scripts/tao_peoplenet/data/people_processed.webm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca549590",
   "metadata": {},
   "source": [
    "## Tensor Interoperability and Combining Custom Operators with Core Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9c201-0493-4426-8961-47dd86121fd5",
   "metadata": {},
   "source": [
    "An operator is the most basic unit of work in this framework. An Operator receives streaming data at an input port, processes it, and publishes it to one of its output ports. The operators included in the SDK provide domain-agnostic functionalities such as IO, machine learning inference, processing, and visualization, they are optimized for AI streaming pipelines.\n",
    "\n",
    "When assembling a C++ application, two types of [operators](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_create_operator.html#c-operators) can be used: native C++ operators and GXF Operators.\n",
    "When assembling a Python application, two types of [operators](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_create_operator.html#python-operators) can be used: native Python operators and Python wrappings of C++ Operators.\n",
    "\n",
    "One of the Holoscan core functionalities is the interoperability between wrapped and native Python operators.\n",
    "\n",
    "For you, the developer, this means:\n",
    "- There is zero copy data movement as one transitions from core Holoscan operators to custom ones\n",
    "- Holoscan supports the [`__cuda_array_interface__`](https://numba.readthedocs.io/en/stable/cuda/cuda_array_interface.html), meaning there is zero copy data movement between C++ and Python operators, in addition to between Python library that support the array standadr. With this support, we can use GPU-accelerated Python libraries such as CuPy, PyTorch, RAPIDs directly in native Holoscan Python operators.\n",
    "\n",
    "To read a Holoscan/GXF tensor object into an Operator and convert it into a CuPy array\n",
    "\n",
    "\n",
    "```python\n",
    "def compute(self, op_input, op_output, context):\n",
    "    # The op_input.receive() method call returns a dict object: in_message\n",
    "    in_message = op_input.receive(\"input_tensor\")\n",
    "        \n",
    "    # go through the dict where the key is the tensor name and the value is the tensor\n",
    "    for key, value in in_message.items():\n",
    "        # each tensor in in_message is now tuend into a CuPy array\n",
    "        cp_array = cp.asarray(value)\n",
    "```\n",
    "\n",
    "If we already know the tensor name we want to access in the input message, for example \"name1\", we can access it by:\n",
    "\n",
    "```python\n",
    "def compute(self, op_input, op_output, context):\n",
    "    in_message = op_input.receive(\"input_tensor\")\n",
    "    specific_tensor = in_message[\"name1\"]\n",
    "    cp_array = cp.asarray(specific_tensor)\n",
    "```\n",
    "\n",
    "\n",
    "To convert a CuPy array to a Holoscan/GXF tensor object and emit it from an Operator\n",
    "```python\n",
    "def compute(self, op_input, op_output, context):\n",
    "    in_message = op_input.receive(\"input_tensor\")\n",
    "    # out_message is of dict\n",
    "    out_message = dict()\n",
    "    # iterate through in_message to \n",
    "    for key, value in in_message.items():\n",
    "        # each tensor in in_message is now tuend into a CuPy array\n",
    "        cp_array = cp.asarray(value)\n",
    "        # modify each CuPy array with your processing logic here   \n",
    "        # ...      \n",
    "        out_message[key] = cp_array\n",
    "    # op_output emits a dict object, with the same format: \n",
    "    # the key is the tensor name and the value is the tensor\n",
    "    op_output.emit(out_message, \"output_tensor\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0cb90",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3298051",
   "metadata": {},
   "source": [
    "Build a custom operator that accepts two tensor input streams from a Core Holoscan Operator at the custom operator's ports `input_1` and `input_2`. We only want to convert two tensors with names `\"original_value\"` from `input_1` and `\"current_value\"` from `input_2` to CuPy arrays and take the difference of these two tensors, regardless of which other tensors may be present in ports `input_1` and `input_2`. Emit the result from an operator with the knowledge that the next in the application pipeline is also a Core Holoscan Operator, through an output port `output` and with the tensor name `\"diff\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094676b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TO-DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60519ab0-7371-4f7b-961f-f1f81b3fad81",
   "metadata": {},
   "source": [
    "Click [here](scripts/answers/ex4.py) to view the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e592a85d-b5d0-40fa-8ff0-b719c19bb991",
   "metadata": {},
   "source": [
    "## Optimizing Your Application\n",
    "### Performance Tool - Data Flow Tracking\n",
    "\n",
    "The Holoscan SDK provides the [Data Flow Tracking](https://docs.nvidia.com/holoscan/sdk-user-guide/flow_tracking.html) APIs as a mechanism to profile your application and analyze the data flow between operators in the graph of a fragment.\n",
    "\n",
    "Enabling flow tracker is easy. We modify an existing app definition and app run command:\n",
    "```python\n",
    "app = MyApp()\n",
    "app.run()\n",
    "```\n",
    "to include using data flow tracking:\n",
    "```python\n",
    "from holoscan.core import Tracker\n",
    "\n",
    "app = MyApp()\n",
    "# set the tracker params\n",
    "with Tracker(app, filename=\"logger.log\", num_start_messages_to_skip=2, num_last_messages_to_discard=3) as tracker:\n",
    "    app.run()\n",
    "    tracker.print() # this is optional\n",
    "```\n",
    "Let's take a look at these two details:\n",
    "\n",
    "`filename=\"logger.log\"`: When logging is enabled by specifying `filename`, every messages received and sent timestamps at every operator between the root and the leaf operators are logged after a message has been processed at the leaf operator.\n",
    "\n",
    "`tracker.print()`: Calling `print()` prints all data flow tracking results including end-to-end latencies and the number of source messages to the standard output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03641b66-88cd-4abe-b42b-3a344199585b",
   "metadata": {},
   "source": [
    "### Scheduler Selection\n",
    "It is essential to select the right scheduler for your use case at hand to ensure optimal performance and efficient resource utilization.\n",
    "\n",
    "The Holoscan SDK offers the following schedulers:\n",
    "* Greedy Scheduler: This basic single-threaded scheduler tests conditions in a greedy manner. Suitable for simple use cases and provides predictable execution. However, it may not be ideal for large-scale applications as it may incur significant overhead in condition execution.\n",
    "\n",
    "* MultiThread Scheduler: It is designed to handle complex execution patterns in large-scale applications. This scheduler consists of a dispatcher thread that periodically polls the status of each operator and dispatches it to a thread pool of worker threads responsible for executing them. Once execution is complete, worker threads enqueue the operator back on the dispatch queue. The MultiThread Scheduler offers superior performance and scalability over the Greedy Scheduler.\n",
    "\n",
    "* Event-Based Scheduler: The event-based scheduler is also a multi-thread scheduler, but as the name indicates it is event-based rather than polling based. Instead of having a thread that constantly polls for the execution readiness of each operator, it instead waits for an event to be received which indicates that an operator is ready to execute. The event-based scheduler will have a lower latency than using the multi-thread scheduler with a long polling interval (check_recession_period_ms), but without the high CPU usage seen for a multi-thread scheduler with a very short polling interval.\n",
    "\n",
    "To set the MultiThread or Event-based scheduler for your app, it is simple via `app.scheduler()`.\n",
    "\n",
    "Note: Explicitly setting GreedyScheduler is not strictly required as it is the default.\n",
    "\n",
    "```python\n",
    "app = MyApp()\n",
    "app.config(\"config-file-name.yaml\")\n",
    "\n",
    "greedy_scheduler = GreedyScheduler(\n",
    "    app,\n",
    "    max_duration_ms=-1, # setting this to -1 will make the app run until all work is done; if positive number is given, the app will run for this amount of time (in ms)\n",
    "    stop_on_deadlock=True,\n",
    "    stop_on_deadlock_timeout=500, # in ms\n",
    "    name=\"greedy_scheduler\",\n",
    ")\n",
    "\n",
    "multithread_scheduler = MultiThreadScheduler(\n",
    "    app,\n",
    "    worker_thread_number=8,\n",
    "    check_recession_period_ms=5, # time periods (in ms) between polling operators\n",
    "    max_duration_ms=-1,\n",
    "    stop_on_deadlock=True,\n",
    "    stop_on_deadlock_timeout=500, # in ms\n",
    "    name=\"multithread_scheduler\",\n",
    ")\n",
    "\n",
    "event_based_scheduler = EventBasedScheduler(\n",
    "    app,\n",
    "    worker_thread_number=8,\n",
    "    max_duration_ms=-1,\n",
    "    stop_on_deadlock=True,\n",
    "    stop_on_deadlock_timeout=500, # in ms\n",
    "    name=\"event_based_scheduler\",\n",
    ")\n",
    "\n",
    "\n",
    "app.scheduler(multithread_scheduler)\n",
    "app.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ee7de-b36e-42ed-98cd-92fc9a98e042",
   "metadata": {},
   "source": [
    "### Seeing the Impact of Scheduler Selection with Flow Tracker\n",
    "In this example, we will see the impact of scheduler selection on the application latency, measured by the Flow Tracker. In this simple app, there is one transmitter, many delay operators defined by `num_delay_ops`, and one receiver. The app only emits a signal once from the transmitter then terminates.\n",
    "\n",
    "<img src=\"images/multithread.png\" width=600/>\n",
    "\n",
    "The latency range below will be different on each instance depending on the hardware, here the latency numbers are just for reference.\n",
    "\n",
    "With the Greedy Scheduler, with 32 delay ops, the avg latency is 3220 ms.\n",
    "\n",
    "With the Multithread Scheduler, with 32 delay ops, 8 threads, 5 ms recess time, the avg latency is 415 ms.\n",
    "\n",
    "With the Event-Based Scheduler, with 32 delay ops, 8 threads, the avg latency is 410 ms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd62ec6-ed14-480a-a1c7-f038c78dc463",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "Run the application defined in [tracker_and_schedulers.py](./scripts/flow_tracker/tracker_and_schedulers.py) to see the latencies with different configurations on your instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a14b48a-85da-4e18-b366-a1869f490dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 8 threads, with 32 parallel delays ops each delaying 0.1 in the command below.\n",
    "# Uncomment the appropriate line to run the app with a selected scheduler\n",
    "# Modify the --threads parameter to set the number of threads for the MultiThread or Event-based schedulers.\n",
    "\n",
    "! python ./scripts/flow_tracker/tracker_and_schedulers.py --scheduler \"greedy\" --threads 1 --num_delay_ops 32 --delay 0.1 --delay_step 0.00\n",
    "# ! python ./scripts/flow_tracker/tracker_and_schedulers.py --scheduler \"multithread\" --threads 8 --recession 5 --num_delay_ops 32 --delay 0.1 --delay_step 0.00\n",
    "# ! python ./scripts/flow_tracker/tracker_and_schedulers.py --scheduler \"event-based\" --threads 8 --num_delay_ops 32 --delay 0.1 --delay_step 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e1feb-1367-4d9a-8430-493570a49cd7",
   "metadata": {},
   "source": [
    "## The Ability to Create a Distributed Application\n",
    "Distributed applications refer to those where the workflow is divided into multiple fragments that may be run on separate nodes. For example, data might be collected via a sensor at the edge, sent to a separate workstation for processing, and then the processed data could be sent back to the edge node for visualization. \n",
    "\n",
    "The multi fragment feature is built on UCX, which can utilize highly optimized network connectivity such as RDMA.\n",
    "\n",
    "The multi fragment functionality is useful in scenarios where we need to:\n",
    "* Scale one application across many copies, on many hardware locations;\n",
    "* Isolate multiple compute workloads, such as CUDA processing, AI inferencing, and visualization;\n",
    "* Have additional compute;\n",
    "* Visualize data from sensors that are physically far away;\n",
    "\n",
    "A single fragment consists of a computation graph built up of operators, and is equivalent to a non-distributed application.\n",
    "\n",
    "We can define each fragment with its operator(s) similarly to how we can define an app: create the operators, use `self.app_operator` to add the operator(s) to each fragment, and use `self.add_flow` among operators within each fragment.\n",
    "\n",
    "```python\n",
    "class Fragment1(Fragment):\n",
    "    def compose(self):\n",
    "        # Configure the operators. Here we use CountCondition to terminate\n",
    "        # execution after a specific number of messages have been sent.\n",
    "        up = UpstreamOp(self, CountCondition(self, 10), name=\"upstream\")\n",
    "        middle = MiddleOp (self, name = \"middle\")\n",
    "\n",
    "        # Add the operators to the fragment\n",
    "        self.add_operator(up)\n",
    "        self.add_operator(middle)\n",
    "        \n",
    "        # Add connection\n",
    "        self.add_flow(up, middle)\n",
    "```\n",
    "Then in the application, we create each fragment, then use `self.add_flow` to connect the fragments.\n",
    "\n",
    "```python\n",
    "class MyDistributedApp(Application):\n",
    "    def compose(self):\n",
    "        fragment1 = Fragment1(self, name=\"fragment1\")\n",
    "        fragment2 = Fragment2(self, name=\"fragment2\")\n",
    "        self.add_flow(fragment1, fragment2, {(\"frag1_out_op.out\", \"frag2_in_op.in\")})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed81f46-a10f-4ac1-b0ab-f7ad57058b58",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "Modify `MyPingApp` defined below to separate `PingTxOp` and `PingRxOp` into two fragments. Assume `PingTxOp` has output port name `out`, `PingRxOp` has input port name `in`. use CountCondition. End the app run after 10 messages had been sent.\n",
    "\n",
    "\n",
    "```python\n",
    "from holoscan.conditions import CountCondition\n",
    "from holoscan.core import Application, Fragment\n",
    "from holoscan.operators import PingRxOp, PingTxOp\n",
    "\n",
    "\n",
    "class MyPingApp(Application):\n",
    "    def compose(self):\n",
    "        # Define the tx and rx operators, allowing tx to execute 10 times\n",
    "        tx = PingTxOp(self, CountCondition(self, 10), name=\"tx\")\n",
    "        rx = PingRxOp(self, name=\"rx\")\n",
    "\n",
    "        # Define the workflow:  tx -> rx\n",
    "        self.add_fow(tx, rx)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = MyPingApp()\n",
    "    app.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc03e2b-f7d3-4bee-8f37-cebb31774507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32df63a0-3b8f-48bd-acca-c5eab84521f0",
   "metadata": {},
   "source": [
    "Click [here](scripts/answers/ex6.py) to view the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a120c4-bc28-4938-87ce-0c310cff8df2",
   "metadata": {},
   "source": [
    "## Application Packaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee5721b",
   "metadata": {},
   "source": [
    "A Holoscan application can be converted into a [Holoscan Application Package (HAP)](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_packager.html) which is an extension of the MONAI Application Package (MAP) specification. A HAP is a containerized run-time environment for a Holoscan application or service, and is built using the Holoscan application package command-line utility. Once the application package has been created, the application can be easily deployed using the Holoscan application packager utility.\n",
    "\n",
    "A HAP is a container image conforming to Holoscan specifications. The primary component of a HAP is the application which is provided by the developer and incorporated into the HAP using the Holoscan Application Packager. Application code and binaries are located in the /opt/holoscan/app/ folder, except for any dependencies installed by the Holoscan Application Packager during the creation of the HAP. All AI models (PyTorch, TensorFlow, TensorRT, etc.) should be in separate sub-folders of the /opt/holoscan/models/ folder or mapped into the HAP container at run-time using the volume-mount command-line options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa43f67-1621-474f-925d-376c5c67ecb1",
   "metadata": {},
   "source": [
    "### Application Packaging Example\n",
    "\n",
    "This example shows how to package a Holoscan Application into a HAP container using the Holoscan CLI. Note that building and running a HAP requires running docker commands, and this lab is likely already running inside a container. This prevents actually running the commands, but you can download the referenced files and build the application package on your own system. For this example, we will use the `ping` sample Python application.\n",
    "\n",
    "*Visit the [SDK User Guide](https://docs.nvidia.com/holoscan/sdk-user-guide/) to learn more about the Holoscan Packager.*\n",
    "\n",
    "#### Setup the Holoscan CLI\n",
    "\n",
    "Refer to the documentation in the [user guide](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_packager.html).\n",
    "\n",
    "#### Define configurations\n",
    "\n",
    "The packager will require a `--platform` and a `--platform-config`. We set them here as a prerequisite for this example. Refer to the user guide for other possible configurations.\n",
    "```\n",
    "$ export gpu_mode=dgpu\n",
    "$ export platform=x64-workstation\n",
    "```\n",
    "\n",
    "Next, we set the Holoscan install directory, and the path to the application configuration file:\n",
    "```\n",
    "$ export holoscan_dir=/opt/nvidia/holoscan\n",
    "$ export holoscan_app_config_path=/workspace/python/scripts/ping/ping.yaml\n",
    "```\n",
    "\n",
    "We then define the path to the application:\n",
    "```\n",
    "$ export holoscan_app_path=/workspace/python/scripts/ping/ping.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ad290-6d78-477e-b156-f53104c6b3b2",
   "metadata": {},
   "source": [
    "#### Run the packager\n",
    "\n",
    "This command will create a docker container that includes the application:\n",
    "\n",
    "```\n",
    "holoscan package -t ping-app \\\n",
    "  --platform $platform \\\n",
    "  --platform-config $gpu_mode \\\n",
    "  --config $holoscan_app_config_path \\\n",
    "  $holoscan_app_path\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef18ecc-174d-46a8-b78f-3821f738b84d",
   "metadata": {},
   "source": [
    "#### Run the containerized application\n",
    "\n",
    "Given the configurations listed in the instructions above, that would be:\n",
    "\n",
    "```\n",
    "$ holoscan run ping-app-x64-workstation-dgpu-linux-amd64:<version-of-image>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a89988",
   "metadata": {},
   "source": [
    "## Explore More Examples with Holohub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd13b7f",
   "metadata": {},
   "source": [
    "The majority of this tutorial has been focused on processing video data, but as we saw in our very first Holoscan example and some of the numerical computing examples we built at the beginning, Holoscan aims to be sensor and domain agnostic.\n",
    "\n",
    "[Holohub](https://github.com/nvidia-holoscan/holohub) is a community driven repository for hosting sample Holoscan applications and operators and includes many useful tools and examples, ranging from Network I/O to AI + Sensor Processing to ChatBots and Accelerated Computing. Some notable examples:\n",
    "\n",
    "- [Basic Network Operator](https://github.com/nvidia-holoscan/holohub/tree/main/operators/basic_network) - Moves UDP data movement to GPU via Linux Sockets\n",
    "- [Advanced Network Operator](https://github.com/nvidia-holoscan/holohub/tree/main/operators/advanced_network) - Moves UPD data to GPU via DPDK and GPUDirect RDMA, bypassing the CPU with additional flow control features (must have NIC + GPU)\n",
    "- [Software Defined Radio](https://github.com/nvidia-holoscan/holohub/tree/main/applications/fm_asr) - [FM Demodulation](https://github.com/nvidia-holoscan/holohub/tree/main/applications/sdr_fm_demodulation) and real-time speech to text transcription\n",
    "- RADAR Pipelines - [Pulse Descriptor Word ID](https://github.com/nvidia-holoscan/holohub/tree/main/applications/simple_pdw_pipeline) and [Simple RADAR Pipeline](https://github.com/nvidia-holoscan/holohub/tree/main/applications/simple_radar_pipeline)\n",
    "- [Speech to Text LLM](https://github.com/nvidia-holoscan/holohub/tree/main/applications/speech_to_text_llm) - Transcribe audio and summarize output\n",
    "\n",
    "And much, much more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b89c5e",
   "metadata": {},
   "source": [
    "### Exercise 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271722d3",
   "metadata": {},
   "source": [
    "Take this opportunity to think about the types of applications you could port to Holoscan. Now think about the Operators you'd need to do that work. Please use the cell below to sketch out your vision. If you feel inclined, write some code or ask a TA about next steps! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398be115",
   "metadata": {},
   "source": [
    "## Future Work and Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a064a",
   "metadata": {},
   "source": [
    "Thank you so much for your attention and interest in Holoscan. We are excited for you to start building your own applications and contributing your work to Holohub!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aec5663",
   "metadata": {},
   "source": [
    "## Licensing\n",
    "\n",
    "Copyright  2024 OpenACC-Standard.org. This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials may include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
